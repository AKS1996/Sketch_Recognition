{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os\n",
    "import ast\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "plt.rcParams['font.size'] = 14\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import multiply, Permute\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "\n",
    "start = dt.datetime.now()\n",
    "\n",
    "def squeeze_excite_block(input, ratio=16):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = init._keras_shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import add\n",
    "from keras.layers import multiply\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "__all__ = ['SEResNet', 'SEResNet50', 'SEResNet101', 'SEResNet154', 'preprocess_input', 'decode_predictions']\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = \"\"\n",
    "WEIGHTS_PATH_NO_TOP = \"\"\n",
    "\n",
    "\n",
    "def SEResNet(input_shape=None,\n",
    "             initial_conv_filters=64,\n",
    "             depth=[3, 4, 6, 3],\n",
    "             filters=[64, 128, 256, 512],\n",
    "             width=1,\n",
    "             bottleneck=False,\n",
    "             weight_decay=1e-4,\n",
    "             include_top=True,\n",
    "             weights=None,\n",
    "             input_tensor=None,\n",
    "             pooling=None,\n",
    "             classes=1000):\n",
    "    \"\"\" Instantiate the Squeeze and Excite ResNet architecture. Note that ,\n",
    "        when using TensorFlow for best performance you should set\n",
    "        `image_data_format=\"channels_last\"` in your Keras config\n",
    "        at ~/.keras/keras.json.\n",
    "        The model are compatible with both\n",
    "        TensorFlow and Theano. The dimension ordering\n",
    "        convention used by the model is the one\n",
    "        specified in your Keras config file.\n",
    "        # Arguments\n",
    "            initial_conv_filters: number of features for the initial convolution\n",
    "            depth: number or layers in the each block, defined as a list.\n",
    "                ResNet-50  = [3, 4, 6, 3]\n",
    "                ResNet-101 = [3, 6, 23, 3]\n",
    "                ResNet-152 = [3, 8, 36, 3]\n",
    "            filter: number of filters per block, defined as a list.\n",
    "                filters = [64, 128, 256, 512\n",
    "            width: width multiplier for the network (for Wide ResNets)\n",
    "            bottleneck: adds a bottleneck conv to reduce computation\n",
    "            weight_decay: weight decay (l2 norm)\n",
    "            include_top: whether to include the fully-connected\n",
    "                layer at the top of the network.\n",
    "            weights: `None` (random initialization) or `imagenet` (trained\n",
    "                on ImageNet)\n",
    "            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "                to use as image input for the model.\n",
    "            input_shape: optional shape tuple, only to be specified\n",
    "                if `include_top` is False (otherwise the input shape\n",
    "                has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "                or `(3, 224, 224)` (with `th` dim ordering).\n",
    "                It should have exactly 3 inputs channels,\n",
    "                and width and height should be no smaller than 8.\n",
    "                E.g. `(200, 200, 3)` would be one valid value.\n",
    "            pooling: Optional pooling mode for feature extraction\n",
    "                when `include_top` is `False`.\n",
    "                - `None` means that the output of the model will be\n",
    "                    the 4D tensor output of the\n",
    "                    last convolutional layer.\n",
    "                - `avg` means that global average pooling\n",
    "                    will be applied to the output of the\n",
    "                    last convolutional layer, and thus\n",
    "                    the output of the model will be a 2D tensor.\n",
    "                - `max` means that global max pooling will\n",
    "                    be applied.\n",
    "            classes: optional number of classes to classify images\n",
    "                into, only to be specified if `include_top` is True, and\n",
    "                if no `weights` argument is specified.\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "        \"\"\"\n",
    "\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    assert len(depth) == len(filters), \"The length of filter increment list must match the length \" \\\n",
    "                                       \"of the depth list.\"\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=32,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=False)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = _create_se_resnet(classes, img_input, include_top, initial_conv_filters,\n",
    "                          filters, depth, width, bottleneck, weight_decay, pooling)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnext')\n",
    "\n",
    "    # load weights\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def SEResNet18(input_shape=None,\n",
    "               width=1,\n",
    "               bottleneck=False,\n",
    "               weight_decay=1e-4,\n",
    "               include_top=True,\n",
    "               weights=None,\n",
    "               input_tensor=None,\n",
    "               pooling=None,\n",
    "               classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[2, 2, 2, 2],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet34(input_shape=None,\n",
    "               width=1,\n",
    "               bottleneck=False,\n",
    "               weight_decay=1e-4,\n",
    "               include_top=True,\n",
    "               weights=None,\n",
    "               input_tensor=None,\n",
    "               pooling=None,\n",
    "               classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[3, 4, 6, 3],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet50(input_shape=None,\n",
    "               width=1,\n",
    "               bottleneck=True,\n",
    "               weight_decay=1e-4,\n",
    "               include_top=True,\n",
    "               weights=None,\n",
    "               input_tensor=None,\n",
    "               pooling=None,\n",
    "               classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet101(input_shape=None,\n",
    "                width=1,\n",
    "                bottleneck=True,\n",
    "                weight_decay=1e-4,\n",
    "                include_top=True,\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[3, 6, 23, 3],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def SEResNet154(input_shape=None,\n",
    "                width=1,\n",
    "                bottleneck=True,\n",
    "                weight_decay=1e-4,\n",
    "                include_top=True,\n",
    "                weights=None,\n",
    "                input_tensor=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "    return SEResNet(input_shape,\n",
    "                    depth=[3, 8, 36, 3],\n",
    "                    width=width,\n",
    "                    bottleneck=bottleneck,\n",
    "                    weight_decay=weight_decay,\n",
    "                    include_top=include_top,\n",
    "                    weights=weights,\n",
    "                    input_tensor=input_tensor,\n",
    "                    pooling=pooling,\n",
    "                    classes=classes)\n",
    "\n",
    "\n",
    "def _resnet_block(input, filters, k=1, strides=(1, 1)):\n",
    "    ''' Adds a pre-activation resnet block without bottleneck layers\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "        strides: strides of the convolution layer\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(input)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if strides != (1, 1) or init._keras_shape[channel_axis] != filters * k:\n",
    "        init = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "                      use_bias=False, strides=strides)(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False, strides=strides)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False)(x)\n",
    "\n",
    "    # squeeze and excite block\n",
    "    x = squeeze_excite_block(x)\n",
    "\n",
    "    m = add([x, init])\n",
    "    return m\n",
    "\n",
    "\n",
    "def _resnet_bottleneck_block(input, filters, k=1, strides=(1, 1)):\n",
    "    ''' Adds a pre-activation resnet block with bottleneck layers\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "        strides: strides of the convolution layer\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    bottleneck_expand = 4\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(input)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if strides != (1, 1) or init._keras_shape[channel_axis] != bottleneck_expand * filters * k:\n",
    "        init = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "                      use_bias=False, strides=strides)(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False, strides=strides)(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_normal',\n",
    "               use_bias=False)(x)\n",
    "\n",
    "    # squeeze and excite block\n",
    "    x = squeeze_excite_block(x)\n",
    "\n",
    "    m = add([x, init])\n",
    "    return m\n",
    "\n",
    "\n",
    "def _create_se_resnet(classes, img_input, include_top, initial_conv_filters, filters,\n",
    "                      depth, width, bottleneck, weight_decay, pooling):\n",
    "    '''Creates a SE ResNet model with specified parameters\n",
    "    Args:\n",
    "        initial_conv_filters: number of features for the initial convolution\n",
    "        include_top: Flag to include the last dense layer\n",
    "        filters: number of filters per block, defined as a list.\n",
    "            filters = [64, 128, 256, 512\n",
    "        depth: number or layers in the each block, defined as a list.\n",
    "            ResNet-50  = [3, 4, 6, 3]\n",
    "            ResNet-101 = [3, 6, 23, 3]\n",
    "            ResNet-152 = [3, 8, 36, 3]\n",
    "        width: width multiplier for network (for Wide ResNet)\n",
    "        bottleneck: adds a bottleneck conv to reduce computation\n",
    "        weight_decay: weight_decay (l2 norm)\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "    Returns: a Keras Model\n",
    "    '''\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    N = list(depth)\n",
    "\n",
    "    # block 1 (initial conv block)\n",
    "    x = Conv2D(initial_conv_filters, (7, 7), padding='same', use_bias=False, strides=(2, 2),\n",
    "               kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay))(img_input)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # block 2 (projection block)\n",
    "    for i in range(N[0]):\n",
    "        if bottleneck:\n",
    "            x = _resnet_bottleneck_block(x, filters[0], width)\n",
    "        else:\n",
    "            x = _resnet_block(x, filters[0], width)\n",
    "\n",
    "    # block 3 - N\n",
    "    for k in range(1, len(N)):\n",
    "        if bottleneck:\n",
    "            x = _resnet_bottleneck_block(x, filters[k], width, strides=(2, 2))\n",
    "        else:\n",
    "            x = _resnet_block(x, filters[k], width, strides=(2, 2))\n",
    "\n",
    "        for i in range(N[k] - 1):\n",
    "            if bottleneck:\n",
    "                x = _resnet_bottleneck_block(x, filters[k], width)\n",
    "            else:\n",
    "                x = _resnet_block(x, filters[k], width)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(classes, use_bias=False, kernel_regularizer=l2(weight_decay),\n",
    "                  activation='softmax')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DP_DIR = '/home/k.vincent/'\n",
    "INPUT_DIR = '/home/k.vincent/apm_file/'\n",
    "BASE_SIZE = 256\n",
    "NCSVS = 100\n",
    "NCATS = 340\n",
    "np.random.seed(seed=1987)\n",
    "tf.set_random_seed(seed=1987)\n",
    "def f2cat(filename: str) -> str:\n",
    "    return filename.split('.')[0]\n",
    "\n",
    "def list_all_categories():\n",
    "    files = os.listdir(os.path.join(INPUT_DIR, 'train_simplified'))\n",
    "    return sorted([f2cat(f) for f in files], key=str.lower)\n",
    "\n",
    "def apk(actual, predicted, k=3):\n",
    "    \"\"\"\n",
    "    Source: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "    \"\"\"\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=3):\n",
    "    \"\"\"\n",
    "    Source: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n",
    "\n",
    "\n",
    "def preds2catids(predictions):\n",
    "    return pd.DataFrame(np.argsort(-predictions, axis=1)[:, :3], columns=['a', 'b', 'c'])\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top3_acc( tgt, pred ):\n",
    "    sc = np.mean( (pred[:,0]==tgt) | (pred[:,1]==tgt) | (pred[:,2]==tgt) )\n",
    "    return sc\n",
    "\n",
    "def custom_single_cnn(size):\n",
    "    model = SEResNet34(input_shape=(size, size, 3), classes=340)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 64)   9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 64)   36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 64)   36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1, 4)      256         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1, 64)     256         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           multiply_1[0][0]                 \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36864       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   36864       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 1, 4)      256         reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 1, 64)     256         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           multiply_2[0][0]                 \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36864       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   36864       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 64)           0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 64)     0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 1, 4)      256         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1, 64)     256         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 32, 32, 64)   0           conv2d_7[0][0]                   \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           multiply_3[0][0]                 \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 128)  73728       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 128)  147456      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 128)          0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 1, 8)      1024        reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 1, 128)    1024        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 16, 16, 128)  0           conv2d_10[0][0]                  \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  8192        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           multiply_4[0][0]                 \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 128)  147456      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 128)  147456      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 128)          0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 1, 8)      1024        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1, 1, 128)    1024        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 16, 16, 128)  0           conv2d_12[0][0]                  \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 128)  0           multiply_5[0][0]                 \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 128)  147456      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 128)  147456      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 128)          0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 1, 8)      1024        reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1, 1, 128)    1024        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 16, 16, 128)  0           conv2d_14[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 128)  0           multiply_6[0][0]                 \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 128)  147456      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 128)  147456      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 128)          0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1, 1, 8)      1024        reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1, 1, 128)    1024        dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 16, 16, 128)  0           conv2d_16[0][0]                  \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 128)  0           multiply_7[0][0]                 \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 256)    294912      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 256)    1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 256)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 256)    589824      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 256)          0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1, 1, 16)     4096        reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1, 1, 256)    4096        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 8, 8, 256)    0           conv2d_19[0][0]                  \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 256)    32768       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 256)    0           multiply_8[0][0]                 \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 256)    1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 256)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 256)    589824      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 256)    1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 256)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 256)    589824      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 256)          0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1, 1, 16)     4096        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1, 1, 256)    4096        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 8, 8, 256)    0           conv2d_21[0][0]                  \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 256)    0           multiply_9[0][0]                 \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 256)    1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 256)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 256)    589824      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 256)    1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 256)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 256)    589824      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Gl (None, 256)          0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1, 1, 16)     4096        reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1, 1, 256)    4096        dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 8, 8, 256)    0           conv2d_23[0][0]                  \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 256)    0           multiply_10[0][0]                \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 256)    1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 256)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 256)    589824      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 256)    1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 256)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 256)    589824      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 256)          0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1, 1, 16)     4096        reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1, 1, 256)    4096        dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 8, 8, 256)    0           conv2d_25[0][0]                  \n",
      "                                                                 dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 256)    0           multiply_11[0][0]                \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 256)    1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 256)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 256)    589824      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 256)    1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 256)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 256)    589824      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_12 (Gl (None, 256)          0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1, 1, 16)     4096        reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1, 1, 256)    4096        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 8, 8, 256)    0           conv2d_27[0][0]                  \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           multiply_12[0][0]                \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 8, 256)    1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 256)    589824      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 256)    1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 256)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 256)    589824      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 256)          0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1, 1, 16)     4096        reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 1, 1, 256)    4096        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 8, 8, 256)    0           conv2d_29[0][0]                  \n",
      "                                                                 dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 256)    0           multiply_13[0][0]                \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 256)    1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 256)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 4, 4, 512)    1179648     activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 4, 4, 512)    2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 512)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 4, 4, 512)    2359296     activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_14 (Gl (None, 512)          0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1, 1, 32)     16384       reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 1, 1, 512)    16384       dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 4, 4, 512)    0           conv2d_32[0][0]                  \n",
      "                                                                 dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 4, 4, 512)    131072      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 512)    0           multiply_14[0][0]                \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 4, 512)    2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 512)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 4, 4, 512)    2359296     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 4, 512)    2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 512)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 4, 4, 512)    2359296     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_15 (Gl (None, 512)          0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 1, 1, 32)     16384       reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1, 1, 512)    16384       dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 4, 4, 512)    0           conv2d_34[0][0]                  \n",
      "                                                                 dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 512)    0           multiply_15[0][0]                \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 4, 4, 512)    2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 4, 512)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 4, 512)    2359296     activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 4, 4, 512)    2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 4, 4, 512)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 4, 4, 512)    2359296     activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_16 (Gl (None, 512)          0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 1, 1, 32)     16384       reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 1, 1, 512)    16384       dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 4, 4, 512)    0           conv2d_36[0][0]                  \n",
      "                                                                 dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 512)    0           multiply_16[0][0]                \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 4, 4, 512)    2048        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 512)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_17 (Gl (None, 512)          0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 340)          174080      global_average_pooling2d_17[0][0]\n",
      "==================================================================================================\n",
      "Total params: 21,629,376\n",
      "Trainable params: 21,614,144\n",
      "Non-trainable params: 15,232\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "bi_factor = 4\n",
    "STEPS = 1000\n",
    "size = 128\n",
    "batchsize = 512\n",
    "\n",
    "model = custom_single_cnn(size=size)\n",
    "model.compile(optimizer=Adam(lr=0.002), loss='categorical_crossentropy',\n",
    "               metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEPS = 1000\n",
    "size = 128\n",
    "batchsize = 512\n",
    "\n",
    "\n",
    "colors = [(255, 0, 0) , (255, 255, 0),  (128, 255, 0),  (0, 255, 0), (0, 255, 128), (0, 255, 255), \n",
    "          (0, 128, 255), (0, 0, 255), (128, 0, 255), (255, 0, 255)]\n",
    "def draw_cv2(raw_strokes, size=256, lw=6):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE,3), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            color = colors[min(t, len(colors)-1)]\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), color, lw, lineType=cv2.LINE_AA)\n",
    "    if np.random.rand()>0.5:\n",
    "        img = np.fliplr(img)\n",
    "    if np.random.rand()>0.75:\n",
    "        if np.random.rand()>0.50:\n",
    "            img = img[ 4:, 4: ,:]\n",
    "        else:\n",
    "            img = img[ :-4, :-4 ,:]\n",
    "    if np.random.rand()>0.50:\n",
    "        img2 = cv2.resize(img, (200, 200))\n",
    "        img = np.zeros((BASE_SIZE, BASE_SIZE,3), np.uint8)\n",
    "        img[18:218,18:218, :] = img2\n",
    "\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size))\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def image_generator(size, batchsize, ks, lw=6):\n",
    "    while True:\n",
    "        for k in np.random.permutation(ks):\n",
    "            filename = os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(k))\n",
    "            for df in pd.read_csv(filename, chunksize=batchsize):\n",
    "                df['drawing'] = df['drawing'].apply(ast.literal_eval)\n",
    "                x = np.zeros((len(df), size, size,3))\n",
    "                for i, raw_strokes in enumerate(df.drawing.values):\n",
    "                    #print(df.drawing.values)\n",
    "                    #\n",
    "                    x[i, :, :, :] = draw_cv2(raw_strokes, size=size, lw=lw)\n",
    "                x = x / 255.\n",
    "                x = x.reshape((len(df), size, size, 3)).astype(np.float32)\n",
    "                y = keras.utils.to_categorical(df.y, num_classes=NCATS)\n",
    "                yield x, y\n",
    "\n",
    "def df_to_image_array(df, size, lw=6):\n",
    "    df['drawing'] = df['drawing'].apply(ast.literal_eval)\n",
    "    x = np.zeros((len(df), size, size,3))\n",
    "    for i, raw_strokes in enumerate(df.drawing.values):\n",
    "        #\n",
    "        x[i, :, : ,:] = draw_cv2(raw_strokes, size=size, lw=lw)\n",
    "    x = x / 255.\n",
    "    x = x.reshape((len(df), size, size, 3)).astype(np.float32)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 128, 128, 3) (30000, 340)\n",
      "Validation array memory 5.49 GB\n"
     ]
    }
   ],
   "source": [
    "valid_df = pd.read_csv(os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(NCSVS - 1)), nrows=30000)\n",
    "x_valid = df_to_image_array(valid_df, size)\n",
    "y_valid = keras.utils.to_categorical(valid_df.y, num_classes=NCATS)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print('Validation array memory {:.2f} GB'.format(x_valid.nbytes / 1024.**3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = image_generator(size=size, batchsize=batchsize, ks=range(NCSVS - 1))\n",
    "val_datagen = image_generator(size=size, batchsize=batchsize, ks=range(NCSVS - 1, NCSVS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1980s 2s/step - loss: 0.7903 - categorical_crossentropy: 0.7551 - categorical_accuracy: 0.8035 - top_3_accuracy: 0.9258 - val_loss: 0.7880 - val_categorical_crossentropy: 0.7528 - val_categorical_accuracy: 0.8032 - val_top_3_accuracy: 0.9263\n",
      "\n",
      "Epoch 00001: val_top_3_accuracy improved from -inf to 0.92632, saving model to ./black-white-7.model\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1984s 2s/step - loss: 0.7885 - categorical_crossentropy: 0.7533 - categorical_accuracy: 0.8041 - top_3_accuracy: 0.9258 - val_loss: 0.7807 - val_categorical_crossentropy: 0.7455 - val_categorical_accuracy: 0.8060 - val_top_3_accuracy: 0.9270\n",
      "\n",
      "Epoch 00002: val_top_3_accuracy improved from 0.92632 to 0.92695, saving model to ./black-white-7.model\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1992s 2s/step - loss: 0.7910 - categorical_crossentropy: 0.7559 - categorical_accuracy: 0.8040 - top_3_accuracy: 0.9254 - val_loss: 0.7867 - val_categorical_crossentropy: 0.7516 - val_categorical_accuracy: 0.8038 - val_top_3_accuracy: 0.9261\n",
      "\n",
      "Epoch 00003: val_top_3_accuracy did not improve from 0.92695\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1986s 2s/step - loss: 0.7919 - categorical_crossentropy: 0.7568 - categorical_accuracy: 0.8030 - top_3_accuracy: 0.9254 - val_loss: 0.7754 - val_categorical_crossentropy: 0.7404 - val_categorical_accuracy: 0.8059 - val_top_3_accuracy: 0.9277\n",
      "\n",
      "Epoch 00004: val_top_3_accuracy improved from 0.92695 to 0.92771, saving model to ./black-white-7.model\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1989s 2s/step - loss: 0.7886 - categorical_crossentropy: 0.7536 - categorical_accuracy: 0.8039 - top_3_accuracy: 0.9260 - val_loss: 0.7735 - val_categorical_crossentropy: 0.7385 - val_categorical_accuracy: 0.8072 - val_top_3_accuracy: 0.9285\n",
      "\n",
      "Epoch 00005: val_top_3_accuracy improved from 0.92771 to 0.92854, saving model to ./black-white-7.model\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1988s 2s/step - loss: 0.7750 - categorical_crossentropy: 0.7400 - categorical_accuracy: 0.8072 - top_3_accuracy: 0.9276 - val_loss: 0.7929 - val_categorical_crossentropy: 0.7579 - val_categorical_accuracy: 0.8021 - val_top_3_accuracy: 0.9255\n",
      "\n",
      "Epoch 00006: val_top_3_accuracy did not improve from 0.92854\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1987s 2s/step - loss: 0.7849 - categorical_crossentropy: 0.7500 - categorical_accuracy: 0.8045 - top_3_accuracy: 0.9266 - val_loss: 0.7817 - val_categorical_crossentropy: 0.7467 - val_categorical_accuracy: 0.8051 - val_top_3_accuracy: 0.9271\n",
      "\n",
      "Epoch 00007: val_top_3_accuracy did not improve from 0.92854\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1983s 2s/step - loss: 0.7596 - categorical_crossentropy: 0.7246 - categorical_accuracy: 0.8105 - top_3_accuracy: 0.9298 - val_loss: 0.7890 - val_categorical_crossentropy: 0.7540 - val_categorical_accuracy: 0.8020 - val_top_3_accuracy: 0.9253\n",
      "\n",
      "Epoch 00008: val_top_3_accuracy did not improve from 0.92854\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1984s 2s/step - loss: 0.7719 - categorical_crossentropy: 0.7370 - categorical_accuracy: 0.8083 - top_3_accuracy: 0.9282 - val_loss: 0.7806 - val_categorical_crossentropy: 0.7457 - val_categorical_accuracy: 0.8057 - val_top_3_accuracy: 0.9279\n",
      "\n",
      "Epoch 00009: val_top_3_accuracy did not improve from 0.92854\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1985s 2s/step - loss: 0.7934 - categorical_crossentropy: 0.7585 - categorical_accuracy: 0.8027 - top_3_accuracy: 0.9252 - val_loss: 0.7816 - val_categorical_crossentropy: 0.7467 - val_categorical_accuracy: 0.8057 - val_top_3_accuracy: 0.9258\n",
      "\n",
      "Epoch 00010: val_top_3_accuracy did not improve from 0.92854\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    #EarlyStopping(monitor='val_top_3_accuracy', patience=15, min_delta=0.001, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=5, min_delta=0.005, mode='max', cooldown=3),\n",
    "    ModelCheckpoint(\"./black-white-7.model\",monitor='val_top_3_accuracy', mode = 'max', save_best_only=True, verbose=1)\n",
    "]\n",
    "hist = model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=10, verbose=1,\n",
    "    validation_data=val_datagen,validation_steps = 150,\n",
    "    callbacks = callbacks\n",
    ")\n",
    "\n",
    "model.save('Autosaved_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 2065s 2s/step - loss: 0.7785 - categorical_crossentropy: 0.7437 - categorical_accuracy: 0.8060 - top_3_accuracy: 0.9273 - val_loss: 0.7847 - val_categorical_crossentropy: 0.7499 - val_categorical_accuracy: 0.8042 - val_top_3_accuracy: 0.9267\n",
      "\n",
      "Epoch 00001: val_top_3_accuracy improved from -inf to 0.92669, saving model to ./black-white-7.model\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 2048s 2s/step - loss: 0.7755 - categorical_crossentropy: 0.7407 - categorical_accuracy: 0.8071 - top_3_accuracy: 0.9275 - val_loss: 0.7793 - val_categorical_crossentropy: 0.7445 - val_categorical_accuracy: 0.8057 - val_top_3_accuracy: 0.9283\n",
      "\n",
      "Epoch 00002: val_top_3_accuracy improved from 0.92669 to 0.92832, saving model to ./black-white-7.model\n",
      "Epoch 3/3\n",
      " 759/1000 [=====================>........] - ETA: 7:36 - loss: 0.7548 - categorical_crossentropy: 0.7201 - categorical_accuracy: 0.8118 - top_3_accuracy: 0.9303"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-90ac747fa758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_datagen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_datagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    #EarlyStopping(monitor='val_top_3_accuracy', patience=15, min_delta=0.001, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=5, min_delta=0.005, mode='max', cooldown=3),\n",
    "    ModelCheckpoint(\"./black-white-7.model\",monitor='val_top_3_accuracy', mode = 'max', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "hist = model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=3, verbose=1,\n",
    "    validation_data=val_datagen,validation_steps = 150,\n",
    "    callbacks = callbacks\n",
    ")\n",
    "\n",
    "model.save('Autosaved_CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If you have enough memory then ship this\n",
    "#remove previous test data: \n",
    "try:\n",
    "    del test\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del x_test\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del x_test2\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del test_predictions1\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del test_predictions2\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del test_predictions\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del top3\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del submission\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del top3cats\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del x_valid2\n",
    "    del valid_predictions1\n",
    "    del valid_predictions2\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#Remove training data. Do so when training 64*64 model\n",
    "try:\n",
    "    del x_valid\n",
    "    del y_valid\n",
    "    del valid_df\n",
    "    del x\n",
    "    pass\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Submission\n",
    "#batched prediction due to memory constrain\n",
    "INPUT_DIR = '/home/k.vincent/'\n",
    "test = pd.read_csv(os.path.join(INPUT_DIR, 'test_simplified.csv'))\n",
    "\n",
    "test_predictions1 = np.zeros(shape=(0,340))\n",
    "test_predictions2 = np.zeros(shape=(0,340))\n",
    "\n",
    "for index, ob in test.groupby(np.arange(len(test))//8000):\n",
    "    x_test = df_to_image_array(ob, size)\n",
    "    x_test2 = np.array( [ np.fliplr(x_test[i]) for i in range(x_test.shape[0])] )\n",
    "    \n",
    "    temp_pred = model.predict(x_test, batch_size=128, verbose=1)\n",
    "    test_predictions1 = np.concatenate((test_predictions1, temp_pred))\n",
    "    \n",
    "    temp_pred = model.predict(x_test2, batch_size=128, verbose=1)\n",
    "    test_predictions2 = np.concatenate((test_predictions2, temp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radio</td>\n",
       "      <td>stereo</td>\n",
       "      <td>alarm_clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hockey_puck</td>\n",
       "      <td>bottlecap</td>\n",
       "      <td>pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_Great_Wall_of_China</td>\n",
       "      <td>castle</td>\n",
       "      <td>fence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mountain</td>\n",
       "      <td>tent</td>\n",
       "      <td>The_Eiffel_Tower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>campfire</td>\n",
       "      <td>fireplace</td>\n",
       "      <td>leaf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         a          b                 c\n",
       "0                    radio     stereo       alarm_clock\n",
       "1              hockey_puck  bottlecap              pool\n",
       "2  The_Great_Wall_of_China     castle             fence\n",
       "3                 mountain       tent  The_Eiffel_Tower\n",
       "4                 campfire  fireplace              leaf"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(112199, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000003627287624</td>\n",
       "      <td>radio stereo alarm_clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000010688666847</td>\n",
       "      <td>hockey_puck bottlecap pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000023642890129</td>\n",
       "      <td>The_Great_Wall_of_China castle fence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000038588854897</td>\n",
       "      <td>mountain tent The_Eiffel_Tower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000052667981386</td>\n",
       "      <td>campfire fireplace leaf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                  word\n",
       "0  9000003627287624              radio stereo alarm_clock\n",
       "1  9000010688666847            hockey_puck bottlecap pool\n",
       "2  9000023642890129  The_Great_Wall_of_China castle fence\n",
       "3  9000038588854897        mountain tent The_Eiffel_Tower\n",
       "4  9000052667981386               campfire fireplace leaf"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(112199, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction ensembling and write file\n",
    "test_predictions = 1*test_predictions1 + 0*test_predictions2\n",
    "INPUT_DIR = '/home/k.vincent/apm_file/'\n",
    "top3 = preds2catids(test_predictions)\n",
    "cats = list_all_categories()\n",
    "id2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(cats)}\n",
    "top3cats = top3.replace(id2cat)\n",
    "top3cats.head()\n",
    "top3cats.shape\n",
    "\n",
    "test['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\n",
    "submission = test[['key_id', 'word']]\n",
    "submission.to_csv('_submit1', index=False)\n",
    "submission.head()\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('seres34_512bat_128reso_full_highe')\n",
    "#model = load_model('black-white-7.model', custom_objects={'top_3_accuracy': top_3_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 40s 1ms/step\n",
      "Map3: 0.858\n",
      "Top3: 0.926\n",
      "\n",
      "30000/30000 [==============================] - 40s 1ms/step\n",
      "Map3: 0.857\n",
      "Top3: 0.926\n",
      "\n",
      "Map3: 0.860\n",
      "Top3: 0.927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy? \n",
    "valid_predictions1 = model.predict(x_valid, batch_size=128, verbose=1)\n",
    "map3 = mapk(valid_df[['y']].values, preds2catids(valid_predictions1).values)\n",
    "top3 = top3_acc(valid_df[['y']].values.flatten(), preds2catids(valid_predictions1).values)\n",
    "print('Map3: {:.3f}'.format(map3))\n",
    "print('Top3: {:.3f}'.format(top3))\n",
    "print()\n",
    "\n",
    "x_valid2 = np.array( [ np.fliplr(x_valid[i]) for i in range(x_valid.shape[0])] )\n",
    "valid_predictions2 = model.predict(x_valid2, batch_size=128, verbose=1)\n",
    "map3 = mapk(valid_df[['y']].values, preds2catids(valid_predictions2).values)\n",
    "top3 = top3_acc(valid_df[['y']].values.flatten(), preds2catids(valid_predictions2).values)\n",
    "print('Map3: {:.3f}'.format(map3))\n",
    "print('Top3: {:.3f}'.format(top3))\n",
    "print()\n",
    "\n",
    "map3 = mapk(valid_df[['y']].values, preds2catids(0.5*valid_predictions1+0.5*valid_predictions2).values)\n",
    "top3 = top3_acc(valid_df[['y']].values.flatten(), preds2catids(0.5*valid_predictions1+0.5*valid_predictions2).values)\n",
    "print('Map3: {:.3f}'.format(map3))\n",
    "print('Top3: {:.3f}'.format(top3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
